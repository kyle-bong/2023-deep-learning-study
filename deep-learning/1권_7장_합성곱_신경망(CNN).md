# Summary

- CNN은 지금까지의 완전 연결 신경망에 합성곱 계층과 풀링 계층이 추가된 네트워크이다.
  - CNN을 사용하면 데이터의 형상이 유지된다는 장점이 있다.
  - 합성곱 계층과 풀링 계층은 im2col을 이용하여 간단하고 효율적으로 구현할 수 있다.
  - CNN을 시각화해보면 계층이 깊어질수록 추상화된 고급 정보가 추출된다.
- 대표적인 CNN에는 LeNet과 AlexNet이 있다.
- 딥러닝의 발전에는 빅데이터와 GPU가 크게 기여했다.


<br/><br/><br/>


# 1. 전체구조

<img width="470" alt="스크린샷 2023-06-30 오후 9 05 28" src="https://user-images.githubusercontent.com/59877415/250083852-5f2aabbe-a0e5-466d-a61d-b298309067a7.png">
Affine 계층을 사용한 5층의 완전 연결 신경망

> 완전 연결 신경망 : 인접하는 모든 계층의 뉴런과 결합되어 있는 신경망



<img width="471" alt="스크린샷 2023-06-30 오후 9 05 33" src="https://user-images.githubusercontent.com/59877415/250083888-0f1ff7d8-83cb-40b4-bace-38c5403b9e70.png">

합성곱 계층과 풀링 계층이 추가된 CNN 네트워크


<br/><br/><br/>



# 2. 합성곱 계층

### 완전 연결 계층의 문제점

완전 연결 계층에서는 데이터의 형상이 무시된다. (3차원 이미지도 1차원 데이터가 되어 공간적 정보를 잃게 된다.)

한편, 합성곱 계층에서는 형상이 유지되어 CNN이 이미지처럼 형상을 가진 데이터를 제대로 이해할 가능성이 있다.

> **CNN의 용어들**
>
> 특징 맵 : 합성곱 계층의 입출력 데이터
>
> 입력 특징 맵 : 합성곱 계층의 입력 특징 맵
>
> 출력 특징 맵 : 합성곱 계층의 출력 특징 맵



### 합성곱 연산

<img width="363" alt="스크린샷 2023-06-30 오후 9 07 22" src="https://user-images.githubusercontent.com/59877415/250084290-2029ecd5-cb4f-4017-9047-008dc2198fa5.png">

합성곱 연산은 필터 연산으로 필터의 윈도우를 일정 간격으로 이동해가며 입력데이터에 적용하는 방식으로 실행된다.

입력과 필터에 대응하는 원소들끼리 곱한 후 그 총합을 구하는 방식으로 연산이 수행된다. (단일 곱셈 누산)

<img width="285" alt="스크린샷 2023-06-30 오후 9 07 42" src="https://user-images.githubusercontent.com/59877415/250084305-606d3aec-bc4f-4787-a315-9dec2c801355.png">

CNN에서 필터의 매개변수는 가중치에 해당하게 된다.

<img width="279" alt="스크린샷 2023-06-30 오후 9 07 52" src="https://user-images.githubusercontent.com/59877415/250084322-b1fe997b-b848-42bf-8a57-08bcf73f2405.png">

그리고 필터가 적용된 후에 편향이 더해지게 된다. 이 때, 편향은 항상 하나(1X1)만 존재한다.



### 패딩

<img width="333" alt="스크린샷 2023-06-30 오후 9 08 04" src="https://user-images.githubusercontent.com/59877415/250084336-233a21ee-b512-4356-9e7b-8baaae582496.png">

합성곱 연산을 수행하기 전에 입력데이터 주변을 특정 값(예컨대 0)으로 채우는 것을 의미한다.

폭 1짜리 패딩이라고 하면 입력 데이터 사방 1픽셀을 특정 값으로 채우는 것이다.

> **왜 패딩을 사용할까?**
>
> (4, 4) 입력 데이터에 (3, 3) 필터를 적용하면 출력은 (2, 2)가 되어 입력보다 2만큼 줄어든다. 출력의 크기가 1이 되면 합성곱 연산을 적용할 수 없게 된다. 이러한 불상사를 막기 위해 패딩은 주로 출력 크기를 조정할 목적으로 사용한다.



### 스트라이드

<img width="303" alt="스크린샷 2023-06-30 오후 9 09 23" src="https://user-images.githubusercontent.com/59877415/250084881-e2e3dd15-dd50-4b0a-982b-aa6676499f78.png">

필터를 적용하는 위치의 간격을 스트라이드라고 한다.

<img width="332" alt="스크린샷 2023-06-30 오후 9 09 39" src="https://user-images.githubusercontent.com/59877415/250084902-2fcdd3e0-4cb7-4e4d-8884-ed5a31000ad6.png">

출력 크기를 구하는 계산식인데, 어렵지 않게 유도할 수 있다. (이미지에서 네모는 - 이다.)

> **출력크기가 정수가 아니라면?**
>
> 오류를 내주거나 가장 가까운 경우로 반올림해준다.



### 3차원 데이터의 합성곱 연산


3차원 데이터의 필터는 특징 맵이 늘어나 3차원이다.

이때 입력 데이터의 채널의 수와 필터의 채널의 수가 같아야 한다.



### 블록으로 생각하기

<img width="323" alt="스크린샷 2023-06-30 오후 9 09 53" src="https://user-images.githubusercontent.com/59877415/250084909-4c9f1230-95c3-41ba-b286-921ceaac5f24.png">

합성곱 연산의 출력으로 다수의 채널을 내보내려면 다수의 필터를 사용하면 된다.

<img width="333" alt="스크린샷 2023-06-30 오후 9 10 46" src="https://user-images.githubusercontent.com/59877415/250084915-cdda278a-2134-40fc-ab9c-3bccfdc277d6.png">

합성곱 연산에도 편향이 사용된다.



### 배치 처리

<img width="328" alt="스크린샷 2023-06-30 오후 9 12 22" src="https://user-images.githubusercontent.com/59877415/250085142-93b7fbcc-3fcb-48b7-84e3-3fad474af0e0.png">

완전 연결 신경망과 마찬가지로 합성곱 연산도 배치 처리를 지원한다.


<br/><br/><br/>



# 3. 풀링 계층

풀링은 세로, 가로 방향의 공간을 줄이는 연산이다.

> **풀링의 종류**
>
> 최대 풀링 : 대상 영역의 최댓값을 구하는 연산 (이미지 인식 분야에서 주로 사용됨)
>
> 평균 풀링 : 대상 영역의 평균값을 구하는 연산



### 풀링 계층의 특징

풀링 계층은 대상 영역에서 최댓값이나 평균값을 취하는 명확한 처리이므로 특별히 학습할 것이 없다.

<img width="338" alt="스크린샷 2023-06-30 오후 9 13 11" src="https://user-images.githubusercontent.com/59877415/250085431-9072a3b9-2e5d-4c4a-99cf-64324e7b24be.png">

채널마다 독립적으로 계산하므로 입력 데이터의 채널수가 곧 출력 데이터의 채널수가 된다.

<img width="343" alt="스크린샷 2023-06-30 오후 9 13 19" src="https://user-images.githubusercontent.com/59877415/250085444-9ab9908b-3bd6-4cd6-affa-001c441c4023.png">

입력 데이터가 조금 변하더라도 풀링의 결과는 잘 변하지 않는다.


<br/><br/><br/>



# 4. 합성곱/풀링 계층 구현하기

### im2col로 문제를 단순하게 만들기

<img width="330" alt="스크린샷 2023-06-30 오후 9 13 31" src="https://user-images.githubusercontent.com/59877415/250085455-b5fe2c64-3f9d-4499-a626-28cdbb33934f.png">

im2col은 입력데이터를 필터링하기 좋게 전개하는 (펼치는 함수)이다.

<img width="344" alt="스크린샷 2023-06-30 오후 9 13 44" src="https://user-images.githubusercontent.com/59877415/250085463-855a8d45-8208-41f6-97a8-447e4fcd4342.png">

연산이 끝나면 2차원의 출력 데이터를 4차원으로 변형해준다.



### 합성곱 계층 구현하기

<img width="326" alt="스크린샷 2023-06-30 오후 9 15 51" src="https://user-images.githubusercontent.com/59877415/250085873-4bb3a032-b7de-46a1-bb52-a3a6d457ee53.png">

> **주의사항**
>
> 합성곱 계층의 역전파에서는 im2col을 역으로 처리해야한다.



### 풀링 계층 구현하기

<img width="330" alt="스크린샷 2023-06-30 오후 9 16 06" src="https://user-images.githubusercontent.com/59877415/250085888-a3c36753-45ca-4571-96f6-9b5e25affd81.png">

<img width="326" alt="스크린샷 2023-06-30 오후 9 16 13" src="https://user-images.githubusercontent.com/59877415/250085893-04ce9bf1-1cd6-43d9-a4c3-0a5492575466.png">

입력 데이터를 전개하고 행별 최댓값을 구하고 적절한 모양으로 성형한다.


<br/><br/><br/>



# 5. CNN 구현하기

### 3단계로 초기화하기

1. 초기화 인수로 주어진 합성곱 계층의 하이퍼파라미터를 딕셔너리에서 꺼낸다. 그리고 합성곱 계층의 출력 크기를 계산한다.
2. 가중치 매개변수를 초기화한다.
3. CNN을 구성하는 계층들을 생성한다.



### predict 메서드와 손실함수의 값을 구하는 loss 메서드를 사용하여 순전파와 역전파를 반복한다.

코드는 생략


<br/><br/><br/>



# 6. CNN 시각화하기

<img width="334" alt="스크린샷 2023-06-30 오후 9 17 28" src="https://user-images.githubusercontent.com/59877415/250086283-7061fe28-8d6a-46af-8495-55ae3c55225b.png">

학습을 마친 필터는 규칙성 있는 이미지가 되어 있다. 필터는 에지(색상이 바뀐 경계선)와 블롭(국소적으로 덩어리진 영역)을 보고 있다.



<img width="329" alt="스크린샷 2023-06-30 오후 9 17 40" src="https://user-images.githubusercontent.com/59877415/250086289-14e55b42-4c23-4840-b2dd-d3d2d3f32bbc.png">

계층이 깊어질수록 CNN에서 추출되는 정보는 추상화된다고 알려져 있다.


<br/><br/><br/>



# 7. 대표적인 CNN

### LeNet

<img width="330" alt="스크린샷 2023-06-30 오후 9 17 54" src="https://user-images.githubusercontent.com/59877415/250086295-28ce4eab-cb11-4f3d-bd40-5861d43c3c20.png">

1998년에 제안된 손글씨를 인식하는 네트워크이다.

- 20년 전에 제안된 첫 CNN인데 현재의 CNN과의 차이가 그리 크지 않다.
- 합성곱 계층과 풀링계층(정확히는 원소를 줄이기만하는 서브샘플링 계층)을 반복하고, 마지막으로 완전연결 계층을 거치면서 결과를 출력한다.
- 활성화함수로 주로 시그모이드를 사용한다.



### AlexNet

<img width="320" alt="스크린샷 2023-06-30 오후 9 18 01" src="https://user-images.githubusercontent.com/59877415/250086296-7f691a97-b78b-4769-98a1-e16dec4c5b90.png">


2012년에 발표되어 딥러닝 열풍을 일으키는데 큰 역할을 했다.

- 활성화 함수로 ReLU를 사용한다.
- LRN이라는 국소정 정규화를 실시하는 계층을 이용한다.
- 드롭아웃을 사용한다.
